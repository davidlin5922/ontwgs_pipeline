# Long-read Whole Genome Sequencing Pipeline for Structural Variant Detection and Comparison
### *Constructed by David Lin*
A pipeline created for long-read Oxford Nanopore Technologies DNA whole genome sequencing data with comparative visualizations of structural variants
## Introduction

### Background

Long-read whole-genome sequencing (WGS) generated by Oxford Nanopore Technologies (ONT) produces reads capable of spanning complex genomic regions, making them especially valuable for identifying structural variants (SVs) in cancer genomes. (1) To support reproducible analyses and facilitate interrogation of ONT datasets by third parties, a structured workflow is required to process raw FASTQ files, evaluate sequencing quality, align reads to a reference genome, call SVs, and consolidate results into an interpretable format. The dataset selected for demonstration includes subsampled ONT-WGS data from the SiHa cervical cancer cell line, a well-characterized model containing known chromosomal rearrangements, integrated HPV sequences, and tumor-associated SVs. (2)

### Purpose

The goal of this workflow is to create a straightforward and expandable pipeline that allows users to interrogate ONT-WGS data and evaluate structural variation in cancer samples. The workflow is intended to be generalizable so users can replace the example dataset with an arbituary number of samples to perform similar comparative analysis.

### Rationale

A dedicated workflow for ONT-WGS structural variant analysis is urgently needed because long-read cancer genomics remains technically complex, resource-intensive, and highly variable across samples. Without a standardized pipeline, differences in quality control procedures, alignment parameters, and SV calling strategies can lead to inconsistent results that are difficult to compare or reproduce. This workflow addresses that gap by providing a clear, validated, and fully automated process that enables any users without specialized bioinformatics expertise to interrogate ONT-WGS datasets and interpret meaningful SV insights.

This preject is also helpful for my present project on osteosarcoma, a pediatric bone cancer, which contains progound SVs and not well-studied telomere structural alterations. (3) This pipeline will serve as the initial data exploration tool, testing if current SV detection tools are able to address telomeric SVs that was not mappable before long-read sequencing was available.

## Usage

### Installation

This pipeline requires `Conda`/`Miniconda`, `Git`, and `Nextflow`.

[`Conda`](https://docs.conda.io/projects/conda/en/stable/user-guide/install/index.html)/[`Miniconda`](https://www.anaconda.com/docs/getting-started/miniconda/install) is needed to run all the dependencies of this workflow. `Miniconda` is adequate for this pipeline. (`Conda` version 25.9.1 was used in testing, but the latest version should work.)

After you have set up `Conda` environment on your device, please install `Git` and `Nextflow` in your environment.

- [`Git`](https://git-scm.com/install) is for version control. Stay up to date with the latest release! (`Git` version 2.51.0 was used in testing, but the latest version should work.)

- [`Nextflow`](https://www.nextflow.io/docs/latest/install.html#conda) is needed to run the pipeline.  (`Nextflow` version 25.10.1 was used in testing.)

*Skip the documentations, just give me the command:*

```
conda install anaconda::git bioconda::nextflow
```

After installations, clone this repository:

```         
git clone https://github.com/davidlin5922/ontwgs_pipeline.git
```

### Dependencies

*The pipeline will automatically download and use all packages when running, so you do not need to manually download them.*

`<channel>::<package name>==<version>`
``` 
anaconda::matplotlib==3.10.6
anaconda::python=3.12
anaconda::pandas==2.3.3
bioconda::minimap2==2.30
bioconda::nanoplot==1.46.1
bioconda::samtools==1.22.1
bioconda::sniffles==2.7.1
conda-forge::r-base==4.5.2
conda-forge::r-rmarkdown==2.30
hcc::sniffles2-plot==0.2.1
```

### Inputs and Outputs

Directory Structure:

```
└── ontwgs_pipeline/
    ├── config/
    │   ├── FASTQ_paths
    │   └── sample_names
    ├── example/
    │   ├── SiHa-ONT_1000_1.fq
    │   └── SiHa-ONT_1000_2.fq
    ├── images/
    │   └── workflow.png
    ├── results/
    │   └── ...
    ├── scripts/
    │   ├── plot_bamqc.py
    │   └── report.rmd
    ├── work/
    │   └── .../
    ├── .gitignore
    ├── main.nf
    ├── nextflow.config
    ├── params.yaml
    └── README.md
```

#### Parameters

This pipeline has three mandatory parameters: `sample_names`, `FASTQ_paths`, and `reference_genome`. They are set in `params.yaml` by default:

```
sample_names: ./config/sample_names
FASTQ_paths: ./config/FASTQ_paths
reference_genome: <hg19|hg38|CHM13>
```

You need to put in unique sample names (no whitespace) in `config/sample_names` and their corresponding FASTQ filepaths in `config/FASTQ_paths`, one per line.

You must also put in the reference genome you want to use in `params.yaml`. The current available ones are `hg19`/`GRCh37`, `hg38`/`GRCh38`, `CHM13`/`T2T`/`t2t`.

#### Running the Pipeline

After you clone the repository to your device and set your parameters, you can start running the pipeline.

```         
nextflow run main.nf -params-file params.yaml
```

It will take under 10 minutes for the first run to set up all the conda environments.

#### Outputs

The output files will be generated in `results/`:

```
└── ontwgs_pipeline/
    ├── .../
    └── results/
        └── bamqc/
        └── bams/
        └── qc/
        └── sniffles2/
        └── report.html
```

`bamqc`, `qc`, and `sniffles2` all contains folders named by the same_names you gave in which is where the tables and figures in `report.html` originated. `bams` contains all the aligned, sorted, and indexed BAM files for you. `sniffles2` also contains the individual and merged variant calling format (VCF) files.

### Pipeline Overview

![](images/workflow.png)

This pipeline will take in pair-end FASTQ generated by ONT-WGS and go through 4 phases:

1.  Quality Control

`nanoplot` is used to assess the quality of your raw ONT reads, including read-length and read-quality distributions, N50, and yield. Plots and a summary table are generated for each sample to provide an overview before downstream processing. The summary table of all samples are also comsolidated in the `All` tab (if more than one samples are present).

2.  Alignment

Reads are aligned to the reference genome of your choice using `minimap2` and optimized for ONT long-read data. Resulting BAM files are sorted, indexed, and passed through `samtools stats` to quantify alignment quality, mapping metrics, and read-length characteristics. A customized Python script `script/plot_bamqc.py` is used to generate the mapping quality distribution and sequencing depth computed.

3.  Structural Variant Calling

SVs are called using `Sniffles2`, which was designed for long-read data. The pipeline produces per-sample VCF files, SNF files for multi-sample merging, a combined VCF of all samples in the run, which will be used for multi-sample comparison.  Visualizations of the VCF files are built with `sniffles2-plot`.

4.  Result Visualization

All figures, tables, and summary metrics are consolidated into a single `report.html` generated via `RMarkdown`.
The report includes QC plots and metrics, alignment and mapping statistics, read-length and coverage summaries, SV distributions and comparisons across samples, and cohort-level visualizations.

## Sample Run and Expected Results

This pipeline was made for the purpose of comparing the structural variants present between cancer samples from FASTQ to full visualized report. Unfortunately, ONT WGS sequencing data is always very large and takes a long time to run one, let alone more than one full dataset. When a subsample is generated, it's not guaranteed that SVs can be detected within the subset of sequences. However, we can alternatively say that we expect minimum differences in SVs between the two toy samples.


A small toy dataset is included in `example/`. It contains two FASTQ files, each with 1,000 ONT reads derived from the SiHa cell line, originally isolated from fragments of a primary uterine tissue biopsy from a 55-year-old Japanese female patient with squamous cell carcinoma. Because the dataset is intentionally tiny, it is suitable for testing whether the pipeline installs and executes correctly. An example completed report (generated using the CHM13/T2T reference genome) is provided at `results/report.html`. You may use this file as a reference to confirm that your pipeline run produced the expected output. 

This pipeline is designed to compare structural variants across whole-genome cancer samples and produce a fully visualized report containing QC metrics, alignments, and SV calling results. However, full ONT WGS datasets are extremely large and normally require substantial computation time. The toy dataset is a highly reduced subsample, and therefore SV detection sensitivity will be low, since structural variants unlikely appear in the small subset of reads. Coverage will be sparse, resulting in limited or absent calls in some regions. What can be reliably expected the two toy samples should show minimal or no differences in structural variants, and the QC and alignment steps will run fully and produce plots and summary tables.

## References
1. Moustakli E, Christopoulos P, Potiris A, Zikopoulos A, Mavrogianni D, Karampas G, et al. Long-Read Sequencing and Structural Variant Detection: Unlocking the Hidden Genome in Rare Genetic Disorders. Diagnostics. 2025 July 17;15(14):1803. 
2. Adeel MM, Jiang H, Arega Y, Cao K, Lin D, Cao C, et al. Structural Variations of the 3D Genome Architecture in Cervical Cancer Development. Front Cell Dev Biol. 2021 July 23;9:706375. 
3. Rajan S, Zaccaria S, Cannon MV, Cam M, Gross AC, Raphael BJ, et al. Structurally Complex Osteosarcoma Genomes Exhibit Limited Heterogeneity within Individual Tumors and across Evolutionary Time. Cancer Research Communications. 2023 Apr 12;3(4):564–75. 
